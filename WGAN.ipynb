{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo4wTMr1e7Do"
      },
      "source": [
        "# WGAN - Wasserstein GAN\n",
        "\n",
        "As Wasserstein GANs (WGANs) são um tipo de rede adversária generativa proposta em 2017 por pesquisadores do DeepMind e Universidade Federal de Toulouse. Elas trazem as seguintes melhorias:\n",
        "\n",
        "- Utilizam a distance métrica Wasserstein ou \"Earth Mover's Distance\" ao invés da loss function tradicional baseada na entropia cruzada das GANs originais. Isso melhora a estabilidade do treinamento.\n",
        "\n",
        "- O discriminador passa a se chamar \"critic\" e ao invés de classificar as amostras como real ou fake, ele estima quão próximas as amostras geradas estão em relação às amostras reais. \n",
        "\n",
        "- Para garantir lipschitz-continuidade, é utilizado um \"clipping\" dos pesos do critic após cada atualização dos parâmetros. Isso também ajuda na estabilidade.\n",
        "\n",
        "- Não há necessidade de usar nenhuma técnica especial de regularização como dropout, batch normalization etc. O clipping já cumpre esse papel.\n",
        "\n",
        "- Têm mostrado resultados superiores na geração de imagens com mais nitidez e menos artefatos e deformações.\n",
        "\n",
        "- Abriram caminho para variações ainda melhores como as WGAN-GP, que usam gradient penalty ao invés de clipping dos pesos.\n",
        "\n",
        "Portanto, as WGANs representaram um grande avanço na qualidade e desempenho de GANs para geração sintética de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMVXB1kraIjB"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "j8HPcf2FjK20",
        "outputId": "9a850f8a-3954-4887-aa19-475d04725cba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "from IPython import display\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrc5vGanaOae"
      },
      "source": [
        "## Carregamento e pré-processamento da base de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOfn6DnlpBJL",
        "outputId": "438b9d29-1f56-4f94-adfd-99a4ca00d743"
      },
      "outputs": [],
      "source": [
        "(X_treinamento, y_treinamento), (_, _) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoq4rS_3WT9m",
        "outputId": "2e8c4ec5-09f0-400e-a985-76ca4678ab0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_treinamento.shape, y_treinamento.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dNVgd3kmpDRH"
      },
      "outputs": [],
      "source": [
        "X_treinamento = X_treinamento.reshape(X_treinamento.shape[0], 28, 28, 1).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06g673v1eXGh",
        "outputId": "d65f065b-2603-4dd0-e7e2-8e700ec37e47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_treinamento.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zEJGJJ0Ocy8h"
      },
      "outputs": [],
      "source": [
        "X_treinamento = (X_treinamento - 127.5) / 127.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xRm-9YdPc1zV"
      },
      "outputs": [],
      "source": [
        "buffer_size = y_treinamento.shape[0] #60000\n",
        "batch_size = 256\n",
        "\n",
        "X_treinamento = tf.data.Dataset.from_tensor_slices(X_treinamento).shuffle(buffer_size).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sIT22SP8mC8"
      },
      "source": [
        "## Construção do Gerador\n",
        "\n",
        "Usaremos a mesma arquitetura do gerador que usamos na implementação do DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5RG2ttCHpKxu"
      },
      "outputs": [],
      "source": [
        "def cria_gerador():\n",
        "  network = tf.keras.Sequential()\n",
        "\n",
        "  network.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "  network.add(layers.BatchNormalization())\n",
        "  network.add(layers.LeakyReLU())\n",
        "\n",
        "  network.add(layers.Reshape((7,7,256)))\n",
        "\n",
        "  # 7x7x128\n",
        "  network.add(layers.Conv2DTranspose(128, (5,5), padding='same', use_bias=False))\n",
        "  network.add(layers.BatchNormalization())\n",
        "  network.add(layers.LeakyReLU())\n",
        "\n",
        "  # 14x14x64\n",
        "  network.add(layers.Conv2DTranspose(64, (5,5), padding='same', use_bias=False, strides=(2,2)))\n",
        "  network.add(layers.BatchNormalization())\n",
        "  network.add(layers.LeakyReLU())\n",
        "\n",
        "  # 28x28x1\n",
        "  network.add(layers.Conv2DTranspose(1, (5,5), padding='same', use_bias=False, strides=(2,2), activation='tanh'))\n",
        "\n",
        "  network.summary()\n",
        "\n",
        "  return network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEUOGVvcdmeM",
        "outputId": "aec5c486-4577-4ef1-bdb9-7e69e2310d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12544)             1254400   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600      \n",
            "=================================================================\n",
            "Total params: 2,330,944\n",
            "Trainable params: 2,305,472\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "gerador = cria_gerador()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rdmoeo0esgW",
        "outputId": "cb0614cf-0fc7-487e-e1fc-732f33e5c222"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor 'dense_input:0' shape=(None, 100) dtype=float32>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gerador.input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzBTftrxez1L",
        "outputId": "b51bc8fe-59c5-48a2-d195-5aec7ecf00db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.63937443  1.1227146  -0.41092402  1.5801548   0.9543949  -0.21359202\n",
            "   0.3710003   0.9008626   0.42023996  0.14022954 -1.3764865   0.45591733\n",
            "   0.01826428 -0.6867227  -0.79969114 -1.5014062  -0.66544926 -0.19839196\n",
            "   1.1103836  -0.76953983 -0.9595084   0.30406895  0.84101295 -1.326886\n",
            "  -1.2424401   1.0339924   1.2991441  -0.8020605  -0.6858614   0.28949127\n",
            "  -0.23019662 -0.32790157  0.07217992 -0.9806209   0.9455645   1.9437834\n",
            "   1.5177829  -0.6518966   2.4353766  -1.1632833   1.0087515   2.058361\n",
            "  -0.7465639  -1.3727311   0.1575224   0.32046416 -1.5453931   0.32907927\n",
            "  -0.7639711  -0.23719412 -0.5294546  -0.23758245 -0.90683585 -0.9993711\n",
            "  -0.73152244  0.8334986  -1.5831969   1.7961258  -2.5031567  -1.1504161\n",
            "   0.9198676  -1.0806489   0.06230872  1.4446399  -1.3415625  -0.45892814\n",
            "   0.65707    -0.1949543  -0.46234608  0.6459628   1.2175418   0.7989869\n",
            "  -0.20038776 -0.0853157   1.0763913   0.17325819 -0.9858921   1.2672855\n",
            "   1.8746758  -0.62792724  0.7544173  -0.36282426  1.0302418  -0.17560509\n",
            "  -0.7416462   0.9033482   0.7866328   0.57537156  0.23334858 -0.23900712\n",
            "   0.67589337 -1.8399934  -1.2380068  -0.6858618  -0.49218655 -0.396854\n",
            "  -0.2325266   0.83584845 -1.8276284  -1.1861858 ]], shape=(1, 100), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "ruido = tf.random.normal([1, 100])\n",
        "print(ruido)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "OEGH29QvpMQk",
        "outputId": "89095b52-1c50-49b8-d87b-25fa65c04cbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 28, 28, 1)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x200a9b5d470>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "imagem_gerada = gerador(ruido, training = False)\n",
        "print(imagem_gerada.shape)\n",
        "\n",
        "plt.imshow(imagem_gerada[0, :, :, 0], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rICQCewYzE9E"
      },
      "source": [
        "## Construção do Discriminador\n",
        "\n",
        "Obs: No contexto de WGAN, o discriminador é chamado também de Crítico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fvCivRbQpPHu"
      },
      "outputs": [],
      "source": [
        "def cria_discriminador():\n",
        "  network = tf.keras.Sequential()\n",
        "\n",
        "  # 14x14x64\n",
        "  network.add(layers.Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape=[28,28,1]))\n",
        "  network.add(layers.LeakyReLU())\n",
        "  network.add(layers.Dropout(0.3))\n",
        "\n",
        "  # 7x7x128\n",
        "  network.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
        "  network.add(layers.LeakyReLU())\n",
        "  network.add(layers.Dropout(0.3))\n",
        "\n",
        "  network.add(layers.Flatten())\n",
        "  network.add(layers.Dense(1))\n",
        "\n",
        "  network.summary()\n",
        "  return network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aViJYeFqfCNc",
        "outputId": "53fb1f0b-aea1-47b1-e46d-a83a4050103c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 6273      \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminador = cria_discriminador()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U2pNybNfkBF",
        "outputId": "8501457d-ca3a-40e5-b315-b29eb73949d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor 'conv2d_input:0' shape=(None, 28, 28, 1) dtype=float32>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "discriminador.input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpdQNMoTpSDl",
        "outputId": "2ae7973d-3609-4555-a1b2-a7b4c5ebd39a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([[-0.00142067]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "resultado = discriminador(imagem_gerada)\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnRhuK7WkOOr"
      },
      "source": [
        "\n",
        "## Funções de perda **Wasserstein Loss**\n",
        "\n",
        "A perda (*loss*) é a diferença entre o valor esperado da saída do discriminador para imagens autênticas e o valor esperado do discriminador para imagens falsas que foram geradas.\n",
        "\n",
        "* O objetivo do discriminador é maximizar essa diferença, enquanto que o objetivo do gerador é minimizar.\n",
        "\n",
        "Então, podemos criar o loss/perda para podermos monitorar os estágios de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voKO_Pa7kAik",
        "outputId": "49c22079-a026-4967-a6df-ebe63176e183"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: id=788, shape=(), dtype=float32, numpy=-0.68333334>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "-1 * tf.math.reduce_mean([0.2, 0.9, 0.95])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9eX_VM3cj1Rz"
      },
      "outputs": [],
      "source": [
        "def loss_gerador(fake_saida):\n",
        "  g_loss = -1. * tf.math.reduce_mean(fake_saida)\n",
        "  return g_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hmoRph3Qkiz-"
      },
      "outputs": [],
      "source": [
        "def loss_discriminador(real_saida, fake_saida, gradient_penalty):\n",
        "  c_lambda = 10\n",
        "  d_loss = tf.math.reduce_mean(fake_saida) - tf.math.reduce_mean(real_saida) + c_lambda * gradient_penalty\n",
        "  return d_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv0r65nzhctp"
      },
      "source": [
        "## **Gradient Penalty**\n",
        "\n",
        "- Parâmetros beta: https://stats.stackexchange.com/questions/265400/deep-learning-how-does-beta-1-and-beta-2-in-the-adam-optimizer-affect-its-lear#:~:text=The%20hyper%2Dparameters%20%CE%B21,each%20training%20step%20(batch).\n",
        "\n",
        " Para usar a perda de Wasserstein, nosso discriminador precisa ser **1-L** [(1-Lipschitz) contínuo](https://www.coursera.org/lecture/build-basic-generative-adversarial-networks-gans/1-lipschitz-continuity-enforcement-GMPCt), ou seja, a norma do gradiente deve ser no máximo 1 em cada ponto.\n",
        "\n",
        "Para impor a continuidade de 1-L usaremos o conceito de **Gradient Penalty**.\n",
        "\n",
        "Essa variação foi apelidada de **WGAN-GP** (devido ao uso do **G**radient **P**enalty)\n",
        "\n",
        "(Mais sobre Gradient Penalty [nesse artigo](https://towardsdatascience.com/demystified-wasserstein-gan-with-gradient-penalty-ba5e9b905ead))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYFFkHxdsqp8"
      },
      "source": [
        "Para calcular o gradient penalty faremos o seguinte:\n",
        "1. Calcular uma imagem interpolada da imagem real e fake (`(real_image * epsilon + fake_image * (1 — epsilon))`)\n",
        "2. Calcular o gradiente da saída do discriminador em relação à imagem interpolada. Depois disso, calcular a norma do gradiente.\n",
        "3. Por fim, a penalidade é calculada como uma média do quadrado de (norma - 1), pois queremos que a norma seja próxima de um.\n",
        "\n",
        "Para trabalhar com algumas das operações envolvendo gradiente usamos o  [GradientTape()](https://www.tensorflow.org/api_docs/python/tf/GradientTape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ztgR7vVytcs-"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def gradient_penalty(real, fake, epsilon):\n",
        "  imgs_interpoladas = real * epsilon + fake * (1 - epsilon)\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(imgs_interpoladas)\n",
        "    scores = discriminador(imgs_interpoladas)\n",
        "  gradient = tape.gradient(scores, imgs_interpoladas)[0]\n",
        "  gradient_norm = tf.norm(gradient)\n",
        "  gp = tf.math.reduce_mean((gradient_norm - 1)**2)\n",
        "  return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "H4FEXSTdvnPt"
      },
      "outputs": [],
      "source": [
        "gerador_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1 = 0.5, beta_2 = 0.9)\n",
        "discriminador_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "H0yXVkdcwgzb"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefixo = os.path.join(checkpoint_dir, \"checkpoints\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer = gerador_optimizer,\n",
        "                                 discrimanator_optimizer = discriminador_optimizer,\n",
        "                                 generator=gerador,\n",
        "                                 discriminator=discriminador)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjUcLF4bd10m"
      },
      "source": [
        "## Treinamento da GAN e visualização dos resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "t_amgc10w_u4"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "noise_dim = 100\n",
        "num_amostras = 16\n",
        "seed = tf.random.normal([num_amostras, noise_dim])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms58h-MnxLIu",
        "outputId": "d9bc8813-47dc-4662-bde5-800c90a1e652"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: id=794, shape=(16, 100), dtype=float32, numpy=\n",
              "array([[-9.27187204e-01,  6.88414574e-01,  9.75743495e-03, ...,\n",
              "        -9.43651974e-01, -3.45081873e-02, -2.57509887e-01],\n",
              "       [ 4.41953868e-01,  7.80562579e-04,  9.52664971e-01, ...,\n",
              "        -6.92464888e-01, -9.39844906e-01, -1.11323810e+00],\n",
              "       [-6.51576519e-01, -1.32355809e+00, -5.17938972e-01, ...,\n",
              "         8.52763116e-01, -1.48964271e-01,  1.07990336e+00],\n",
              "       ...,\n",
              "       [ 5.55496931e-01,  5.07702768e-01, -2.19545245e-01, ...,\n",
              "        -1.73714712e-01, -9.71449390e-02,  1.79231495e-01],\n",
              "       [ 1.02526195e-01, -3.14773053e-01,  9.63700116e-01, ...,\n",
              "         6.38835907e-01,  1.02902782e+00, -2.25228652e-01],\n",
              "       [-2.48140669e+00,  2.66927958e-01,  1.05203760e+00, ...,\n",
              "        -9.42845941e-02,  4.18980002e-01, -3.95406693e-01]], dtype=float32)>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Teofu6_9I9YS"
      },
      "outputs": [],
      "source": [
        "def etapa_treinamento(imgs):\n",
        "  noise = tf.random.normal([batch_size, noise_dim])\n",
        "  discriminador_etapas_extras = 3\n",
        "  for i in range(discriminador_etapas_extras):\n",
        "    with tf.GradientTape() as d_tape:\n",
        "      imgs_geradas = gerador(noise, training = True)\n",
        "      real_saida = discriminador(imgs, training = True)\n",
        "      fake_saida = discriminador(imgs_geradas, training=True)\n",
        "      epsilon = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
        "      gp = gradient_penalty(imgs, imgs_geradas, epsilon)\n",
        "\n",
        "      d_loss = loss_discriminador(real_saida, fake_saida, gp)\n",
        "\n",
        "    discriminador_gradients = d_tape.gradient(d_loss, discriminador.trainable_variables)\n",
        "    discriminador_optimizer.apply_gradients(zip(discriminador_gradients, discriminador.trainable_variables))\n",
        "\n",
        "  with tf.GradientTape() as g_tape:\n",
        "    imgs_geradas = gerador(noise, training = True)\n",
        "    fake_saida = discriminador(imgs_geradas, training = True)\n",
        "    g_loss = loss_gerador(fake_saida)\n",
        "  gerador_gradients = g_tape.gradient(g_loss, gerador.trainable_variables)\n",
        "  gerador_optimizer.apply_gradients(zip(gerador_gradients, gerador.trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OEFc8HqZU3P"
      },
      "source": [
        "Sobre logits: https://deepai.org/machine-learning-glossary-and-terms/logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "y3biNFY3PuiU"
      },
      "outputs": [],
      "source": [
        "def gerar_e_salvar_imgs(model, epoch, test_input):\n",
        "  preds = model(test_input, training = False)\n",
        "  fig = plt.figure(figsize = (4,4))\n",
        "  for i in range(preds.shape[0]):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(preds[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "    plt.axis('off')\n",
        "  #plt.savefig('img_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KXZmsbpdPPnW"
      },
      "outputs": [],
      "source": [
        "def treinar(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    inicio = time.time()\n",
        "    for img_batch in dataset:\n",
        "      if len(img_batch) == batch_size:\n",
        "        etapa_treinamento(img_batch)\n",
        "\n",
        "    #display.clear_output(wait = True)\n",
        "    gerar_e_salvar_imgs(gerador, epoch + 1, seed)\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefixo)\n",
        "    print('Tempo para processar época {} foi de {} segundos'.format(epoch + 1, time.time() - inicio))\n",
        "\n",
        "  #display.clear_output(wait = True)\n",
        "  gerar_e_salvar_imgs(gerador, epochs, seed)\n",
        "  gerador.save('gerador.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5q8ObPDiQ__A",
        "outputId": "21c80f85-a4d9-469d-fa8b-6bd7a9e43bf1"
      },
      "outputs": [],
      "source": [
        "treinar(X_treinamento, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noFb1ixUYQ0r",
        "outputId": "064b8285-28cd-4d27-b364-312c6b8870d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fda5035df90>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npSdXoxxYev5",
        "outputId": "67834a45-d6a3-494e-fd6a-f260597f8b47"
      },
      "outputs": [],
      "source": [
        "seed_input = tf.random.normal([num_amostras, noise_dim])\n",
        "preds = gerador(seed_input, training = False)\n",
        "fig = plt.figure(figsize = (4,4))\n",
        "for i in range(preds.shape[0]):\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.imshow(preds[i, :, :, 0] * 127.5 + 127.5, cmap = 'gray')\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUC60XJSjfy3"
      },
      "source": [
        "> Mais implementações:\n",
        "\n",
        "* https://github.com/robbiebarrat/art-DCGAN (baseado em DCGAN)\n",
        "* https://github.com/tdrussell/IllustrationGAN (baseado em DCGAN)\n",
        "* https://github.com/viuts/wgan-animefaces (baseado em WGAN)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
